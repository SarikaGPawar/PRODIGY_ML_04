# PRODIGY_ML_04
# âœ‹ Hand Gesture Recognition using CNN

This project is a deep learning-based hand gesture recognition system built using TensorFlow and the LeapGestRecog dataset. The goal was to classify different hand gestures from grayscale images to enable gesture-based interaction.

## ðŸ“Œ Project Description
I developed a Convolutional Neural Network (CNN) to recognize 10 different hand gestures from the LeapGestRecog dataset. The dataset contains thousands of grayscale images, organized by gesture type and user. The model takes in 64x64 pixel images and outputs the predicted gesture class.

The main steps in the project:
- Loaded and preprocessed gesture images using OpenCV and NumPy
- Normalized image data and converted labels using one-hot encoding
- Built a CNN with convolution, pooling, dropout, and dense layers
- Trained the model using TensorFlow/Keras
- Evaluated model accuracy and tested predictions on unseen images

## ðŸŽ“ What I Learned
- How to work with image datasets and preprocess them for deep learning
- The structure and working of Convolutional Neural Networks (CNNs)
- How to use TensorFlow/Keras to build, compile, and train deep learning models
- How to evaluate a model using accuracy and visualize training performance
- How to use Label Encoding and one-hot encoding for classification tasks
- Improved confidence in handling real-world datasets and building ML projects

This was a great learning experience and helped me understand how deep learning can be applied to real-time image classification tasks like gesture control.

